{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Dataframe creation\n",
    "This notebook loads in the csv files that contain the information extracted by OpenFace from the videos. Each csv file is then loaded into a pandas dataFrame. To this dataframe we add columns containing information about the start (moment) of the TSST speech component. The dataframe is then stored in the `interim` folder as a `.feather`, for use in the sampling and feature computation steps later on.\n",
    "\n",
    "#### Requirements\n",
    "If one wants to run this notebook, one needs to have run the `raw-video-extraction.py` script. The resulting `csv` files need to be stored in `data\\raw\\Video_Features`.\n",
    "\n",
    "Next one, also needs the timing csv file, which denotes the second where the participant starts with the TSST Speech component. This file needs to be stored `data\\information\\` and be called `start_sentence.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mitchel = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading in the required modules, we store the working directory in a variable called `project_dir`. We then store the folder where the data files are located in a variable called `data_dir`. We create a variable that contains the specific names of all the csv files, `raw_feature_files`. We also put the location in which the future created dataframes need to be saved in a variable called `processed_dir`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = os.getcwd().split('\\\\')[:-1]\n",
    "project_dir = '\\\\'.join(project_dir) # Get the project dir\n",
    "# Get the data dir\n",
    "if Mitchel:\n",
    "    data_dir = 'C:\\\\Users\\\\mitch\\\\OneDrive - UGent\\\\UGent\\\\Projects\\\\7. tDCS_Stress_WM_deSmet\\\\data'\n",
    "    data_dir = 'Z:\\\\ghep_lab\\\\2020_DeSmetKappen_tDCS_Stress_WM_VIDEO\\\\Data'\n",
    "else:\n",
    "    data_dir = project_dir + '\\\\data'\n",
    "processed_dir = data_dir + '\\\\raw\\\\Video_features' # Get the dir that contains the processed video features csv files\n",
    "raw_feature_files = [file for file in os.listdir(processed_dir) if file.endswith('csv')] # Get all the csv files in the specific data dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We open the file `start_sentence.csv`, which contain the starting moments of the TSST speech component of each participant. We store this in a dict called `timings` where you can get the moment in the video of a certain participant (pp) where the TSST component starts in seconds (start) as follows:\n",
    "\n",
    "`start = timings['pp']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = csv.DictReader(open(data_dir + '\\\\information\\\\start_sentence.csv', encoding='utf-8-sig'), delimiter=';') # Open the file that contains the starting points of the TSST component in the videos\n",
    "timings = {}\n",
    "for row in reader:\n",
    "    timings[int(row['pp'])] = int(row['start']) # Store this information in a dict for later use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then load in each csv file into a dataframe one by one. We add some information about the participant. Each line corresponds to a single frame in the video and contains the information about that frame extracted by OpenFace. We add to this dataframe a column called `started`, which is `1` if the participant already started the TSST speech component and `0` if nott. We also added information about the how many frames and seconds a specific frame (row) was from the frame in which the TSST speech component started, which can be found in the columns `t_from_start` (seconds) and `frames_away_start` (frames). Each dataframes is then saved in the interim folder as a `.feather` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 2\n",
      "processing 3\n",
      "processing 4\n",
      "processing 5\n",
      "processing 10\n",
      "processing 11\n",
      "processing 12\n",
      "processing 13\n",
      "processing 14\n",
      "processing 17\n",
      "processing 18\n",
      "processing 19\n",
      "processing 21\n",
      "processing 43\n",
      "processing 62\n",
      "processing 68\n",
      "processing 69\n",
      "processing 70\n",
      "processing 71\n",
      "processing 76\n",
      "processing 77\n",
      "processing 82\n",
      "processing 84\n",
      "processing 86\n",
      "processing 90\n",
      "processing 91\n",
      "processing 92\n",
      "processing 93\n",
      "processing 94\n",
      "processing 95\n",
      "processing 96\n",
      "processing 97\n",
      "processing 98\n",
      "pp98 done\n",
      "processing 99\n",
      "pp99 done\n",
      "processing 100\n",
      "pp100 done\n",
      "processing 101\n",
      "pp101 done\n",
      "processing 102\n",
      "pp102 done\n",
      "processing 103\n",
      "pp103 done\n",
      "processing 104\n",
      "pp104 done\n",
      "processing 105\n",
      "pp105 done\n",
      "processing 106\n",
      "pp106 done\n",
      "processing 107\n",
      "pp107 done\n",
      "processing 109\n",
      "pp109 done\n",
      "processing 110\n",
      "pp110 done\n",
      "processing 113\n",
      "pp113 done\n",
      "processing 114\n",
      "pp114 done\n",
      "processing 115\n",
      "pp115 done\n",
      "processing 117\n",
      "pp117 done\n",
      "processing 118\n",
      "pp118 done\n",
      "processing 119\n",
      "pp119 done\n",
      "processing 120\n",
      "pp120 done\n",
      "processing 121\n",
      "pp121 done\n",
      "processing 122\n",
      "pp122 done\n",
      "processing 123\n",
      "pp123 done\n",
      "processing 125\n",
      "pp125 done\n",
      "processing 126\n",
      "pp126 done\n",
      "processing 127\n",
      "pp127 done\n",
      "processing 128\n",
      "pp128 done\n",
      "processing 129\n",
      "pp129 done\n",
      "processing 130\n",
      "pp130 done\n",
      "processing 133\n",
      "pp133 done\n",
      "processing 134\n",
      "pp134 done\n",
      "processing 135\n",
      "pp135 done\n",
      "processing 136\n",
      "pp136 done\n",
      "processing 138\n",
      "pp138 done\n",
      "processing 139\n",
      "pp139 done\n",
      "processing 143\n",
      "pp143 done\n",
      "All done!\n"
     ]
    }
   ],
   "source": [
    "for csv_file in raw_feature_files: # For each csv file\n",
    "    pp = int(csv_file[4:7]) # Get the pp id    \n",
    "    new_data['pp'] = pp # Add this to the DataFrame\n",
    "    print(f'processing {pp}')\n",
    "#     if pp > 97:\n",
    "    if True:\n",
    "        new_data = pd.read_csv(processed_dir + '\\\\' + csv_file) # Open the file as a DataFrame\n",
    "        new_data.columns = [col.strip(' ') for col in new_data.columns] # Remove the blank spaces from the column names (This is the result of how OpenFace exports the csv Files)\n",
    "    \n",
    "\n",
    "        # Add a column `started` which is 0 for the rows when the pp did not yet the TSST speech, and 1 if the pp did start\n",
    "        new_data['started'] = 0 \n",
    "        new_data.loc[(new_data.timestamp >= timings[pp]), 'started'] = 1 # The timing information (when did the pp start) is retrieved from the timings dict using the pp id\n",
    "\n",
    "        ## Add a column `frames_away_start` & `t_from_start` to denote how far each row is from the frame in which the pp started the TSST speech component\n",
    "        ## We need these columns, together with the pp id column to synchronise the physiological and video DataFrame\n",
    "        frame_at_start = new_data.loc[new_data.started==1, 'frame'].values[0] # First find the exact frame in which the participant started\n",
    "        new_data.loc[:, 'frames_away_start'] = new_data.loc[:, 'frame'] - frame_at_start # Compute how far away each frame is from this starting frame by subtracting this from the column `frame`\n",
    "        new_data['t_from_start'] = new_data['frames_away_start']/25 # Add the column `t_from_start`, by deviding `frames_away_start` by 25, which denotes how many seconds each frame is from the starting point\n",
    "\n",
    "        new_data.astype('float',copy=False)# Set the entire dataframe as Float for memory reasons (string takes more memory)\n",
    "\n",
    "        # Reset the index before storing the DataFrame in an feather file for later use\n",
    "        new_data.reset_index(inplace=True)\n",
    "        new_data.to_feather(f'{data_dir}\\\\interim\\\\video\\\\{pp}.feather')\n",
    "        print(f'pp{pp} done')\n",
    "print('All done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ppt_002.csv'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
