{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Physiological Dataframe creation\n",
    "This notebook creates the physiological signal dataframes for each participant. This is done for both the ACQ as well as the AMSDATA files. To both columns we add information about the start (moment) of the TSST speech component. Each created dataframe is stored in the `interim` folder as a `.hdf` file, for use in the sampling and target computation steps later on.\n",
    "#### Requirements\n",
    "To be able to run this notebook one needs to have collected the physiological data files for all the participants. These files need to be saved in `data\\raw\\Physiological`.\n",
    "\n",
    "This notebook handles both the ACQ and AMSDATA files. Since it is not possible to open the AMSDATA files from python, one needs to export the signals to `.txt` files using the AMSDATA software. This will result in two `.txt` files per participant, one for ECG and another one for SCL.\n",
    "\n",
    "Since the AMSDATA does not handle timing information, we also need to collect the timing information for each participant from the session information excel file. This timing information is stored in an `.csv` file in `data\\information`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import bioread\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading in the required modules, we store the working directory in a variable called `project_dir`. We then store the folder where the data files are located in a variable called `physData_dir`. We create a variable that contains the specific names of all the acq files, `acq_files`, as well as a variable for all the txt files (amsdata), `txt_files`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = os.getcwd().split('\\\\')[:-1] \n",
    "project_dir = '\\\\'.join(project_dir) # Get the project dir\n",
    "data_dir = 'C:\\\\Users\\\\mitch\\\\OneDrive - UGent\\\\UGent\\\\Projects\\\\7. tDCS_Stress_WM_deSmet\\\\data'\n",
    "data_dir = 'Z:\\\\ghep_lab\\\\2020_DeSmetKappen_tDCS_Stress_WM_VIDEO\\\\Data'\n",
    "physData_dir = data_dir + '\\\\raw\\\\Physiological'\n",
    "acq_files = [file for file in os.listdir(physData_dir) if file.endswith('acq')] # Find all the acq files in the data dir\n",
    "txt_files = [file[:-7] for file in os.listdir(physData_dir) if file.endswith('SCL.txt')] # Find all the SCL text files in the dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Components\n",
    "Below we select the parts of the physiological signal that was recorded during active components of the experiment. This includes the baseline, TSST preparation, TSST Speech, TSST Math and recovery components. The remaining physiological signal, between the components, is removed. We also store the all the data as a `float` to reduce the amount of memory necessary.\n",
    "### .acq Files\n",
    "We can extract the different components from the `.acq` files using the digital input channel that is present in this data. The components are denoted by an active electronic signal of 5V in the digital input channel, while the time between components is denoted by an inactive signal. We can therefore find the starting points of each component by finding where the difference between consecutive pionts in the digital input channel is positive, indicating an increase from 0V to 5V. Since we now the exact length of each component we can then loop through the starting points corresponding to our desired components (in this case `[0,3,4,5,6]`) and extract the EDA and ECG signal aswell as the corresponding timestamps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acq_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing: pp100s2.acq\n",
      "pp100 done\n",
      "processing: pp101s2.acq\n",
      "pp101 done\n",
      "processing: pp102s2.acq\n",
      "pp102 done\n",
      "processing: pp103s2.acq\n",
      "pp103 done\n",
      "processing: pp104s2.acq\n",
      "pp104 done\n",
      "processing: pp105s2.acq\n",
      "pp105 done\n",
      "processing: pp106s2.acq\n",
      "pp106 done\n",
      "processing: pp107s2.acq\n",
      "pp107 done\n",
      "processing: pp108s2.acq\n",
      "pp108 done\n",
      "processing: pp109s2.acq\n",
      "pp109 done\n",
      "processing: pp10s2.acq\n",
      "pp10 done\n",
      "processing: pp110s2.acq\n",
      "pp110 done\n",
      "processing: pp113s2.acq\n",
      "pp113 done\n",
      "processing: pp114s2.acq\n",
      "pp114 done\n",
      "processing: pp115s2.acq\n",
      "pp115 done\n",
      "processing: pp117s2.acq\n",
      "pp117 done\n",
      "processing: pp118s2.acq\n",
      "pp118 done\n",
      "processing: pp119s2.acq\n",
      "pp119 done\n",
      "processing: pp11s2.acq\n",
      "pp11 done\n",
      "processing: pp120s2.acq\n",
      "pp120 done\n",
      "processing: pp121s2.acq\n",
      "pp121 done\n",
      "processing: pp122s2.acq\n",
      "pp122 done\n",
      "processing: pp123s2.acq\n"
     ]
    },
    {
     "ename": "HDF5ExtError",
     "evalue": "Problems creating the Array.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHDF5ExtError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-907bc274899e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;31m# Reset the index before storing the DataFrame in an HDF file for later use\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m     \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_hdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'{data_dir}\\\\interim\\\\physiological_all\\\\{pp}.hdf'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mf'pp{pp}'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'pp{pp} done'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\stress_video\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_hdf\u001b[1;34m(self, path_or_buf, key, mode, complevel, complib, append, format, index, min_itemsize, nan_rep, dropna, data_columns, errors, encoding)\u001b[0m\n\u001b[0;32m   2604\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpytables\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2605\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2606\u001b[1;33m         pytables.to_hdf(\n\u001b[0m\u001b[0;32m   2607\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2608\u001b[0m             \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\stress_video\\lib\\site-packages\\pandas\\io\\pytables.py\u001b[0m in \u001b[0;36mto_hdf\u001b[1;34m(path_or_buf, key, value, mode, complevel, complib, append, format, index, min_itemsize, nan_rep, dropna, data_columns, errors, encoding)\u001b[0m\n\u001b[0;32m    278\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomplevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcomplevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomplib\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcomplib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m         ) as store:\n\u001b[1;32m--> 280\u001b[1;33m             \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    281\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m         \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\stress_video\\lib\\site-packages\\pandas\\io\\pytables.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(store)\u001b[0m\n\u001b[0;32m    260\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;31m# NB: dropna is not passed to `put`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m         f = lambda store: store.put(\n\u001b[0m\u001b[0;32m    263\u001b[0m             \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m             \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\stress_video\\lib\\site-packages\\pandas\\io\\pytables.py\u001b[0m in \u001b[0;36mput\u001b[1;34m(self, key, value, format, index, append, complib, complevel, min_itemsize, nan_rep, data_columns, encoding, errors, track_times, dropna)\u001b[0m\n\u001b[0;32m   1090\u001b[0m             \u001b[0mformat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_option\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"io.hdf.default_format\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m\"fixed\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1091\u001b[0m         \u001b[0mformat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1092\u001b[1;33m         self._write_to_group(\n\u001b[0m\u001b[0;32m   1093\u001b[0m             \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1094\u001b[0m             \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\stress_video\\lib\\site-packages\\pandas\\io\\pytables.py\u001b[0m in \u001b[0;36m_write_to_group\u001b[1;34m(self, key, value, format, axes, index, append, complib, complevel, fletcher32, min_itemsize, chunksize, expectedrows, dropna, nan_rep, data_columns, encoding, errors, track_times)\u001b[0m\n\u001b[0;32m   1740\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1741\u001b[0m         \u001b[1;31m# write the object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1742\u001b[1;33m         s.write(\n\u001b[0m\u001b[0;32m   1743\u001b[0m             \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1744\u001b[0m             \u001b[0maxes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\stress_video\\lib\\site-packages\\pandas\\io\\pytables.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, obj, **kwargs)\u001b[0m\n\u001b[0;32m   3173\u001b[0m             \u001b[1;31m# I have no idea why, but writing values before items fixed #2299\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3174\u001b[0m             \u001b[0mblk_items\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3175\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"block{i}_values\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mblk_items\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3176\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"block{i}_items\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblk_items\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\stress_video\\lib\\site-packages\\pandas\\io\\pytables.py\u001b[0m in \u001b[0;36mwrite_array\u001b[1;34m(self, key, obj, items)\u001b[0m\n\u001b[0;32m   3050\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_array_empty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3051\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3052\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3054\u001b[0m         \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_v_attrs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransposed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\stress_video\\lib\\site-packages\\tables\\file.py\u001b[0m in \u001b[0;36mcreate_array\u001b[1;34m(self, where, name, obj, title, byteorder, createparents, atom, shape, track_times)\u001b[0m\n\u001b[0;32m   1155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1156\u001b[0m         \u001b[0mparentnode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_or_create_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreateparents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1157\u001b[1;33m         return Array(parentnode, name,\n\u001b[0m\u001b[0;32m   1158\u001b[0m                      \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbyteorder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbyteorder\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1159\u001b[0m                      track_times=track_times)\n",
      "\u001b[1;32m~\\miniconda3\\envs\\stress_video\\lib\\site-packages\\tables\\array.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, parentnode, name, obj, title, byteorder, _log, _atom, track_times)\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m         \u001b[1;31m# Ordinary arrays have no filters: leaf is created with default ones.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 192\u001b[1;33m         super(Array, self).__init__(parentnode, name, new, Filters(),\n\u001b[0m\u001b[0;32m    193\u001b[0m                                     byteorder, _log, track_times)\n\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\stress_video\\lib\\site-packages\\tables\\leaf.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, parentnode, name, new, filters, byteorder, _log, track_times)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 286\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLeaf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparentnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_log\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    287\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\stress_video\\lib\\site-packages\\tables\\node.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, parentnode, name, _log)\u001b[0m\n\u001b[0;32m    262\u001b[0m             \u001b[1;31m#   Create or open the node and get its object ID.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mnew\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_v_objectid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_g_create\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    265\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_v_objectid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_g_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\stress_video\\lib\\site-packages\\tables\\array.py\u001b[0m in \u001b[0;36m_g_create\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    222\u001b[0m             \u001b[1;31m# needed for setting attributes in some descendants later\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m             \u001b[1;31m# on\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m             (self._v_objectid, self.shape, self.atom) = self._create_array(\n\u001b[0m\u001b[0;32m    225\u001b[0m                 nparr, self._v_new_title, self.atom)\n\u001b[0;32m    226\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mtables/hdf5extension.pyx\u001b[0m in \u001b[0;36mtables.hdf5extension.Array._create_array\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mHDF5ExtError\u001b[0m: Problems creating the Array."
     ]
    }
   ],
   "source": [
    "for file in acq_files: # For each acq files in the dir\n",
    "    print(f'processing: {file}')\n",
    "    pp = int(file[2:-6]) # Get the pp id\n",
    "    bio = bioread.read_file(physData_dir + '\\\\' + file) # Open the physiological file\n",
    "    \n",
    "    # Get the EDA, ECG, Time index and Digital input signal(which corresponds to the triggers from the psychopy script)\n",
    "    eda_org = bio.channels[0].data \n",
    "    ecg_org = bio.channels[1].data\n",
    "    timestamps_org = bio.channels[0].time_index    \n",
    "    digital_input_org = np.copy(bio.channels[2].data)\n",
    "    \n",
    "    # Using the Digital input signal, get the start and stop points of the different components in the study\n",
    "    starts = np.where(np.diff(digital_input_org)>0)[0]\n",
    "    stops = np.where(np.diff(digital_input_org)<0)[0]\n",
    "    \n",
    "    # Create empty arrays to store the signals\n",
    "    eda = np.array([])  \n",
    "    ecg = np.array([])\n",
    "    timestamps = np.array([])\n",
    "    digital_input = np.array([])\n",
    "    \n",
    "    active_components = [0,3,4,5,6] # Desired components (Active components in the study)\n",
    "    \n",
    "    for i in active_components:  # For each component\n",
    "        start = starts[i] # Get starting point\n",
    "        stop = stops[i+1] # Get stop point (+1 because the digital signal starts with a stop)\n",
    "        \n",
    "        # Add the EDA, ECG, Time index and Digital input signal between start and stop point to the arrays\n",
    "        eda = np.append(eda, eda_org[start:stop])\n",
    "        ecg = np.append(ecg, ecg_org[start:stop])\n",
    "        timestamps = np.append(timestamps, timestamps_org[start:stop])\n",
    "        digital_input = np.append(digital_input, digital_input_org[start:stop])\n",
    "    \n",
    "    data = pd.DataFrame({'timestamp': timestamps,'raw_EDA': eda, 'raw_ECG': ecg, 'digital_input': digital_input}) # Create a DataFrame with the signals stored in the array\n",
    "    \n",
    "    freq=round(1/(data.timestamp.values[1] - data.timestamp.values[0])) # Compute the frequency of the signals using the following formula: freq=1/(t_1 - t_2)\n",
    "    \n",
    "    data['t_from_start'] = data['timestamp'] - (start/freq) # Compute the time between each row in the DataFrame and the starting point\n",
    "    data['pp'] =  pp # Store the PP_id in the DataFrame\n",
    "    data.astype('float',copy=False) # Set the entire dataframe as Float for memory reasons (string takes more memory)\n",
    "\n",
    "    # Reset the index before storing the DataFrame in an HDF file for later use\n",
    "    data.reset_index(inplace=True) \n",
    "    data.to_hdf(f'{data_dir}\\\\interim\\\\physiological_all\\\\{pp}.hdf', f'pp{pp}', mode='w')\n",
    "    \n",
    "    print(f'pp{pp} done')\n",
    "print('All done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .amsdata files\n",
    "Unlike the `.acq` files, the `.amsdata` files (which are extracted and stored in an `.txt` file) do not denote the different components of the experiment along the physiological signal. Instead, the experimenters in the study have indicated the starting points of each component in an excel file. These starting points are saved in the `amsdata_start.xlsx` file. Because the `.amsdata` is saved in an `.txt` file we can store the raw EDA signal in a pandas dataframe, which allows for easier extraction of the active components, by using the `.loc` method from the Pandas DataFrame object, instead of a for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timings = pd.read_excel(f'{data_dir}\\\\information\\\\amsdata_start.xlsx') # Open the file that contains the starting and stop points in a DataFrame\n",
    "\n",
    "for file in txt_files: # for each SCL text file\n",
    "    pp = int(file[2:-3])  # Get the pp id\n",
    "    start_stops = timings.loc[timings.Participant==pp].values[0][1:] # Subset the DataFrame to only the start and stop point for the current PP, and collect those values\n",
    "    \n",
    "    # Open the EDA and ECG file and merge these two based on their time index\n",
    "    eda_data = pd.read_csv(f'{physData_dir}\\\\{file}SCL.txt', sep=' ', skiprows=3, names=['timestamp', 'raw_EDA'])\n",
    "    ecg_data = pd.read_csv(f'{physData_dir}\\\\{file}ECG.txt', sep=' ', skiprows=3, names=['timestamp', 'raw_ECG'])\n",
    "    data = ecg_data.merge(eda_data, on='timestamp', how='outer')\n",
    "    \n",
    "    \n",
    "    data['timestamp'] = data['timestamp']/1000 # Divide the timestamp collumn by a 1000 since the timestamps are in the txt files are in ms but the starting points from the excel file are in seconds\n",
    "    \n",
    "    freq=round(1/(data.timestamp.values[1] - data.timestamp.values[0])) # Compute the frequency of the signals using the following formula: freq=1/(t_1 - t_2)\n",
    "    \n",
    "    data['pp'] =  pp # Store the PP_id in the DataFrame\n",
    "    \n",
    "    ## Very hard to read code below: Selects the rows from the DataFrame containing the EDA and ECG signal that are between the starting and stop points of the active components\n",
    "    ## This code is faster than looping and appending to arrays. See the comments below for the logic\n",
    "    data = data.loc[((data.timestamp>start_stops[0]) & (data.timestamp<start_stops[1])) # Get each row: (After 1st timepoint in start_stop) AND (before 2nd timepoint in start_stop) OR \n",
    "                    |((data.timestamp>start_stops[2]) & (data.timestamp<start_stops[3])) # (After 3rd timepoint in start_stop) AND (before 4th timepoint in start_stop) OR\n",
    "                    |((data.timestamp>start_stops[4]) & (data.timestamp<start_stops[5])) # And so on...\n",
    "                    |((data.timestamp>start_stops[6]) & (data.timestamp<start_stops[7]))\n",
    "                    |((data.timestamp>start_stops[8]) & (data.timestamp<start_stops[9])),:]\n",
    "    \n",
    "    data.astype('float',copy=False) # Set the entire dataframe as Float for memory reasons (string takes more memory)\n",
    "    \n",
    "    # Reset the index before storing the DataFrame in an HDF file for later use\n",
    "    data.reset_index(inplace=True)\n",
    "    data.to_hdf(f'{data_dir}\\\\interim\\\\physiological_all\\\\{pp}.hdf', f'pp{pp}', mode='w')\n",
    "    print(f'pp{pp} done')\n",
    "    \n",
    "print('All done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSST component\n",
    "Below we extract the TSST component of the experiment. From both the `.acq` files and the `.amsdata` files we extract physiological signal from the TSST speech and TSST math component, aswell as the signal inbetween both components. Because the camera is started a bit before the start of the TSST speech component and the recording lasts around 15 to 20 minutes, it is easier to extract the physiological from 3 minutes prior to the start of the TSST speech component till the 20 minutes after the start of the component. This is once again stored in a `.hdf` file.\n",
    "\n",
    "For this component we also add a `t_from_start` column, which indicates for all the other timepoints in the signal how far away (in seconds) it is removed from the start of the TSST component, which we can use it later on to synchronise it to the video data. \n",
    "### .acq files\n",
    "Once again, we can select the components using the digital input channel present in the `.acq` files. The starting point of TSST speech component is indicated by the 5th time the digital input was activated. We can then use this starting point to select all the EDA and ECG signal from 3 minutes prior till 20 minutes post this starting point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for file in acq_files: # For each acq files in the dir\n",
    "    pp = int(file[2:-6]) # Get the pp id\n",
    "    bio = bioread.read_file(physData_dir + '\\\\' + file) # Open the physiological file\n",
    "\n",
    "    # Get the EDA, ECG, Time index and Digital input signal(which corresponds to the triggers from the psychopy script)\n",
    "    eda = bio.channels[0].data\n",
    "    ecg = bio.channels[1].data\n",
    "    timestamps = bio.channels[0].time_index\n",
    "    digital_input = np.copy(bio.channels[2].data)\n",
    "    \n",
    "    # Using the Digital input signal, get the start and stop points of the different components in the study\n",
    "    starts = np.where(np.diff(digital_input_org)>0)[0]\n",
    "    stops = np.where(np.diff(digital_input_org)<0)[0]\n",
    "    \n",
    "    # Select the starting point of the TSST Speech component and the stopping point of the TSST Math component\n",
    "    start = starts[4]\n",
    "    stop = stops[6]\n",
    "    \n",
    "    # Subset the EDA, ECG, time index and digital input signal, 3 minutes prior to the start of the speech component and 3 minutes past the end of the speech component \n",
    "    eda = eda[start-(2000*60*3):stop+(2000*60*3)]\n",
    "    ecg = ecg[start-(2000*60*3):stop+(2000*60*3)]\n",
    "    timestamps = timestamps[start-(2000*60*3):stop+(2000*60*3)]\n",
    "    digital_input = digital_input[start-(2000*60*3):stop+(2000*60*3)]\n",
    "    \n",
    "    \n",
    "    data = pd.DataFrame({'timestamp': timestamps,'raw_EDA': eda, 'raw_ECG': ecg, 'digital_input': digital_input}) # Create a DataFrame with the signals stored in the array\n",
    "    \n",
    "    freq=round(1/(data.timestamp.values[1] - data.timestamp.values[0])) # Compute the frequency of the signals using the following formula: freq=1/(t_1 - t_2)\n",
    "    \n",
    "    data['t_from_start'] = data['timestamp'] - (start/freq) # Compute the time between each row in the DataFrame and the starting point\n",
    "    data['pp'] =  pp # Store the PP_id in the DataFrame\n",
    "    data.astype('float',copy=False) # Set the entire dataframe as Float for memory reasons (string takes more memory)\n",
    "    \n",
    "    # Reset the index before storing the DataFrame in an HDF file for later use\n",
    "    data.reset_index(inplace=True)\n",
    "    data.to_hdf(f'{data_dir}\\\\interim\\\\physiological\\\\{pp}.hdf', f'pp{pp}', mode='w')\n",
    "    print(f'pp{pp} done')\n",
    "print('All done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .amsdata files\n",
    "As said before the `.amsdata` files (which are extracted and stored in an `.txt` files) do not denote the different components of the experiment along the physiological signal. Instead, the experimenters in the study have indicated the starting points of each component in an excel file. The starting point of the TSST speech component is stored in the `started_TSST.csv` file. We open the file `start_TSST.csv` and store the information inside in a dict called `timings` where you can get the moment in the video of a certain participant (pp) where the TSST component starts in seconds (start) as follows: `start = timings['pp']`.\n",
    "\n",
    "Once agian we we can store the raw EDA signal in a pandas dataframe, which allows for easier extraction of the active components, by using the `.loc` method from the Pandas DataFrame object, instead of a for loop. Likewise to the `.acq` files, we take the subset of the data between 3 minutes prior to the start and 20 minutes after the start. This file is also stored in a `hdf` file in the interim folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the file that contains the starting and stop points for each participant for the start TSST component\n",
    "reader = csv.DictReader(open(project_dir + '\\\\data\\\\information\\\\start_TSST.csv', encoding='utf-8-sig'), delimiter=';')\n",
    "timings = {}\n",
    "for row in reader:\n",
    "    timings[int(row['pp'])] = float(row['start'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in txt_files: # for each SCL text file\n",
    "    pp = int(file[2:-3]) # Get the pp id\n",
    "    start = timings[pp] # Get the starting point of the TSST speech component for this participant\n",
    "    \n",
    "    # Open the EDA and ECG file and merge these two based on their time index\n",
    "    eda_data = pd.read_csv(f'{physData_dir}\\\\{file}SCL.txt', sep=' ', skiprows=3, names=['timestamp', 'raw_EDA'])\n",
    "    ecg_data = pd.read_csv(f'{physData_dir}\\\\{file}ECG.txt', sep=' ', skiprows=3, names=['timestamp', 'raw_ECG'])\n",
    "    data = ecg_data.merge(eda_data, on='timestamp', how='outer')\n",
    "    \n",
    "    data['timestamp'] = data['timestamp']/1000 # Divide the timestamp collumn by a 1000 since the timestamps are in the txt files are in ms but the starting points from the excel file are in seconds\n",
    "\n",
    "    freq=round(1/(data.timestamp.values[1] - data.timestamp.values[0])) # Compute the frequency of the signals using the following formula: freq=1/(t_1 - t_2)\n",
    "    \n",
    "    data['t_from_start'] =  data['timestamp'] - start # Compute the time between each row in the DataFrame and the starting point\n",
    "    data['pp'] =  pp # Store the PP_id in the DataFrame\n",
    "    \n",
    "    data = data.loc[(data.t_from_start>-180) & (data.t_from_start<1200),:] # Subset the rows 3 minutes prior to the TSST Speech starting point and 20 minutes after this starting point\n",
    "    \n",
    "    data.astype('float',copy=False) # Set the entire dataframe as Float for memory reasons (string takes more memory)\n",
    "    \n",
    "    # Reset the index before storing the DataFrame in an HDF file for later use\n",
    "    data.reset_index(inplace=True)\n",
    "    data.to_hdf(f'{data_dir}\\\\interim\\\\physiological\\\\{pp}.hdf', f'pp{pp}', mode='w')\n",
    "    print(f'pp{pp} done')\n",
    "    \n",
    "print('All done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline component"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we want to extract the baseline component of the experiment, since we can use this information for standardisation. This is very very similar to the extraction of the TSST components, where as we now only have to extract one component. The two cells below corresponds to the previous two respectively, in one minor change. We subset only the rows between the starting and end point (minutes after the starting point) of the baseline component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for file in acq_files: # For each acq files in the dir\n",
    "    pp = int(file[2:-6]) # Get the pp id\n",
    "    bio = bioread.read_file(physData_dir + '\\\\' + file) # Open the physiological file\n",
    "    \n",
    "    # Get the EDA, ECG, Time index and Digital input signal(which corresponds to the triggers from the psychopy script)\n",
    "    eda = bio.channels[0].data\n",
    "    ecg = bio.channels[1].data\n",
    "    timestamps = bio.channels[0].time_index\n",
    "    digital_input = np.copy(bio.channels[2].data)\n",
    "    \n",
    "    # Using the Digital input signal, get the start and stop points of the different components in the study\n",
    "    starts = np.where(np.diff(digital_input)>0)[0]\n",
    "    stops = np.where(np.diff(digital_input)<0)[0]\n",
    "    \n",
    "    # Select the start and stop point of the baseline component\n",
    "    start = starts[0]\n",
    "    stop = stops[1]\n",
    "    \n",
    "    # Subset the EDA, ECG, time index and digital input signal\n",
    "    eda = eda[start:stop]\n",
    "    ecg = ecg[start:stop]\n",
    "    timestamps = timestamps[start:stop]\n",
    "    digital_input = digital_input[start:stop]\n",
    "\n",
    "    data = pd.DataFrame({'timestamp': timestamps,'raw_EDA': eda, 'raw_ECG': ecg, 'digital_input': digital_input}) # Create a DataFrame with the signals stored in the array\n",
    "    \n",
    "    freq=round(1/(data.timestamp.values[1] - data.timestamp.values[0])) # Compute the frequency of the signals using the following formula: freq=1/(t_1 - t_2)\n",
    "    \n",
    "    data['t_from_start'] = data['timestamp'] - (start/freq) # Compute the time between each row in the DataFrame and the starting point\n",
    "    data['pp'] =  pp # Store the PP_id in the DataFrame\n",
    "    data.astype('float',copy=False) # Set the entire dataframe as Float for memory reasons (string takes more memory)\n",
    "    \n",
    "    # Reset the index before storing the DataFrame in an HDF file for later use\n",
    "    data.reset_index(inplace=True)\n",
    "    data.to_hdf(f'{data_dir}\\\\interim\\\\physiological_baseline\\\\{pp}.hdf', f'pp{pp}', mode='w')\n",
    "    print(f'pp{pp} done')\n",
    "print('All done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the file that contains the starting and stop points for each participant for the start TSST component\n",
    "reader = csv.DictReader(open(project_dir + '\\\\data\\\\information\\\\start_Baseline.csv', encoding='utf-8-sig'), delimiter=';')\n",
    "timings = {}\n",
    "for row in reader:\n",
    "    timings[int(row['pp'])] = float(row['start'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in txt_files: # for each SCL text file\n",
    "    pp = int(file[2:-3]) # Get the pp id\n",
    "    start = timings[pp] # Get the starting point of the baseline component for this participant\n",
    "    \n",
    "    # Open the EDA and ECG file and merge these two based on their time index\n",
    "    eda_data = pd.read_csv(f'{physData_dir}\\\\{file}SCL.txt', sep=' ', skiprows=3, names=['timestamp', 'raw_EDA'])\n",
    "    ecg_data = pd.read_csv(f'{physData_dir}\\\\{file}ECG.txt', sep=' ', skiprows=3, names=['timestamp', 'raw_ECG'])\n",
    "    data = ecg_data.merge(eda_data, on='timestamp', how='outer')\n",
    "    \n",
    "    data['timestamp'] = data['timestamp']/1000 # Divide the timestamp collumn by a 1000 since the timestamps are in the txt files are in ms but the starting points from the excel file are in seconds\n",
    "    \n",
    "    freq=round(1/(data.timestamp.values[1] - data.timestamp.values[0])) # Compute the frequency of the signals using the following formula: freq=1/(t_1 - t_2)\n",
    "    \n",
    "    data['t_from_start'] =  data['timestamp'] - start # Compute the time between each row in the DataFrame and the starting point\n",
    "    data['pp'] =  pp # Store the PP_id in the DataFrame\n",
    "    \n",
    "    data = data.loc[(data.t_from_start>0) & (data.t_from_start<300),:] # Subset the rows from the baseline starting point till 5 minutes after this starting point\n",
    "    data.astype('float',copy=False) # Set the entire dataframe as Float for memory reasons (string takes more memory)\n",
    "    \n",
    "    # Reset the index before storing the DataFrame in an HDF file for later use\n",
    "    data.reset_index(inplace=True)\n",
    "    data.to_hdf(f'{data_dir}\\\\interim\\\\physiological_baseline\\\\{pp}.hdf', f'pp{pp}', mode='w')\n",
    "    print(f'pp{pp} done')\n",
    "print('All done!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
