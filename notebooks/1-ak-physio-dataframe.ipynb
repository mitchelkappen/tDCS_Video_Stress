{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Physiological Dataframe creation\n",
    "This notebook creates the physiological signal dataframes for each participant. This is done for both the ACQ as well as the AMSDATA files. To both columns we add information about the start (moment) of the TSST speech component. Each created dataframe is stored in the `interim` folder as a `.hdf` file, for use in the sampling and target computation steps later on.\n",
    "#### Requirements\n",
    "To be able to run this notebook one needs to have collected the physiological data files for all the participants. These files need to be saved in `data\\raw\\Physiological`.\n",
    "\n",
    "This notebook handles both the ACQ and AMSDATA files. Since it is not possible to open the AMSDATA files from python, one needs to export the signals to `.txt` files using the AMSDATA software. This will result in two `.txt` files per participant, one for ECG and another one for SCL.\n",
    "\n",
    "Since the AMSDATA does not handle timing information, we also need to collect the timing information for each participant from the session information excel file. This timing information is stored in an `.csv` file in `data\\information`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import bioread\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading in the required modules, we store the working directory in a variable called `project_dir`. We then store the folder where the data files are located in a variable called `data_dir`. We create a variable that contains the specific names of all the acq files, `acq_files`, as well as a variable for all the txt files (amsdata), `txt_files`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = os.getcwd().split('\\\\')[:-1] \n",
    "project_dir = '\\\\'.join(project_dir) # Get the project dir\n",
    "data_dir = project_dir + '\\\\data\\\\raw\\\\Physiological' # Add the specific data dir\n",
    "acq_files = [file for file in os.listdir(data_dir) if file.endswith('acq')] # Find all the acq files in the data dir\n",
    "txt_files = [file[:-7] for file in os.listdir(data_dir) if file.endswith('SCL.txt')] # Find all the SCL text files in the dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Components\n",
    "Below we select the parts of the physiological signal that was recorded during active components of the experiment. This includes the baseline, TSST preparation, TSST Speech, TSST Math and recovery components. The remaining physiological signal, between the components, is removed. We also store the all the data as a `float` to reduce the amount of memory necessary.\n",
    "### .acq Files\n",
    "We can extract the different components from the `.acq` files using the digital input channel that is present in this data. The components are denoted by an active electronic signal of 5V in the digital input channel, while the time between components is denoted by an inactive signal. We can therefore find the starting points of each component by finding where the difference between consecutive pionts in the digital input channel is positive, indicating an increase from 0V to 5V. Since we now the exact length of each component we can then loop through the starting points corresponding to our desired components (in this case `[0,3,4,5,6]`) and extract the EDA and ECG signal aswell as the corresponding timestamps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pp100 done\n",
      "pp101 done\n",
      "pp102 done\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-d77be16e59b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;32min\u001b[0m \u001b[0macq_files\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# For each acq files in the dir\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mpp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Get the pp id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mbio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbioread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_dir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'\\\\'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Open the physiological file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# Get the EDA, ECG, Time index and Digital input signal(which corresponds to the triggers from the psychopy script)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\video_stress\\lib\\site-packages\\bioread\\__init__.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(filelike, channel_indexes, encoding)\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mtarget_chunk_size\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[0mA\u001b[0m \u001b[0mguide\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mnumber\u001b[0m \u001b[0mof\u001b[0m \u001b[0mbytes\u001b[0m \u001b[0mto\u001b[0m \u001b[0mread\u001b[0m \u001b[0mat\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \"\"\"\n\u001b[1;32m---> 26\u001b[1;33m     return reader.Reader.read(filelike, channel_indexes,\n\u001b[0m\u001b[0;32m     27\u001b[0m                               encoding=encoding).datafile\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\video_stress\\lib\\site-packages\\bioread\\reader.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(cls, fo, channel_indexes, target_chunk_size, encoding)\u001b[0m\n\u001b[0;32m     78\u001b[0m             \u001b[0mreader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[0mreader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_headers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m             \u001b[0mreader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchannel_indexes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_chunk_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\video_stress\\lib\\site-packages\\bioread\\reader.py\u001b[0m in \u001b[0;36m_read_data\u001b[1;34m(self, channel_indexes, target_chunk_size)\u001b[0m\n\u001b[0;32m    233\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__read_data_compressed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchannel_indexes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__read_data_uncompressed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchannel_indexes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_chunk_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_read_markers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\video_stress\\lib\\site-packages\\bioread\\reader.py\u001b[0m in \u001b[0;36m__read_data_uncompressed\u001b[1;34m(self, channel_indexes, target_chunk_size)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macq_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_start_offset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m         \u001b[1;31m# This will fill self.datafile.channels with data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m         read_uncompressed(\n\u001b[0m\u001b[0;32m    297\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macq_file\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatafile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchannels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\video_stress\\lib\\site-packages\\bioread\\reader.py\u001b[0m in \u001b[0;36mread_uncompressed\u001b[1;34m(f, channels, channel_indexes, target_chunk_size)\u001b[0m\n\u001b[0;32m    394\u001b[0m     chunker = make_chunk_reader(\n\u001b[0;32m    395\u001b[0m         f, channels, channel_indexes, target_chunk_size)\n\u001b[1;32m--> 396\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mchunk_buffers\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mchunker\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    397\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mchannel_indexes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m             \u001b[0mch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchannels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\video_stress\\lib\\site-packages\\bioread\\reader.py\u001b[0m in \u001b[0;36mread_chunks\u001b[1;34m(f, buffers, byte_pattern, channel_indexes)\u001b[0m\n\u001b[0;32m    433\u001b[0m             chunk_number, chunk_bytes, f.tell()))\n\u001b[0;32m    434\u001b[0m         chunk_data = np.frombuffer(\n\u001b[1;32m--> 435\u001b[1;33m             f.read(chunk_bytes), dtype=\"b\", count=chunk_bytes)\n\u001b[0m\u001b[0;32m    436\u001b[0m         update_buffers_with_data(\n\u001b[0;32m    437\u001b[0m             chunk_data, buffers, pat, channel_indexes)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for file in acq_files: # For each acq files in the dir\n",
    "    pp = int(file[2:-6]) # Get the pp id\n",
    "    bio = bioread.read_file(data_dir + '\\\\' + file) # Open the physiological file\n",
    "    \n",
    "    # Get the EDA, ECG, Time index and Digital input signal(which corresponds to the triggers from the psychopy script)\n",
    "    eda_org = bio.channels[0].data \n",
    "    ecg_org = bio.channels[1].data\n",
    "    timestamps_org = bio.channels[0].time_index    \n",
    "    digital_input_org = np.copy(bio.channels[2].data)\n",
    "    \n",
    "    # Using the Digital input signal, get the start and stop points of the different components in the study\n",
    "    starts = np.where(np.diff(digital_input_org)>0)[0]\n",
    "    stops = np.where(np.diff(digital_input_org)<0)[0]\n",
    "    \n",
    "    # Create empty arrays to store the signals\n",
    "    eda = np.array([])  \n",
    "    ecg = np.array([])\n",
    "    timestamps = np.array([])\n",
    "    digital_input = np.array([])\n",
    "    \n",
    "    active_components = [0,3,4,5,6] # Desired components (Active components in the study)\n",
    "    \n",
    "    for i in active_components:  # For each component\n",
    "        start = starts[i] # Get starting point\n",
    "        stop = stops[i+1] # Get stop point (+1 because the digital signal starts with a stop)\n",
    "        \n",
    "        # Add the EDA, ECG, Time index and Digital input signal between start and stop point to the arrays\n",
    "        eda = np.append(eda, eda_org[start:stop])\n",
    "        ecg = np.append(ecg, ecg_org[start:stop])\n",
    "        timestamps = np.append(timestamps, timestamps_org[start:stop])\n",
    "        digital_input = np.append(digital_input, digital_input_org[start:stop])\n",
    "    \n",
    "    data = pd.DataFrame({'timestamp': timestamps,'raw_EDA': eda, 'raw_ECG': ecg, 'digital_input': digital_input}) # Create a DataFrame with the signals stored in the array\n",
    "    \n",
    "    freq=round(1/(data.timestamp.values[1] - data.timestamp.values[0])) # Compute the frequency of the signals using the following formula: freq=1/(t_1 - t_2)\n",
    "    \n",
    "    data['t_from_start'] = data['timestamp'] - (start/freq) # Compute the time between each row in the DataFrame and the starting point\n",
    "    data['pp'] =  pp # Store the PP_id in the DataFrame\n",
    "    data.astype('float',copy=False) # Set the entire dataframe as Float for memory reasons (string takes more memory)\n",
    "\n",
    "    # Reset the index before storing the DataFrame in an HDF file for later use\n",
    "    data.reset_index(inplace=True) \n",
    "    data.to_hdf(f'{project_dir}\\\\data\\\\interim\\\\physiological_all\\\\{pp}.hdf', f'pp{pp}', mode='w')\n",
    "    \n",
    "    print(f'pp{pp} done')\n",
    "print('All done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .amsdata files\n",
    "Unlike the `.acq` files, the `.amsdata` files (which are extracted and stored in an `.txt` file) do not denote the different components of the experiment along the physiological signal. Instead, the experimenters in the study have indicated the starting points of each component in an excel file. These starting points are saved in the `amsdata_start.xlsx` file. Because the `.amsdata` is saved in an `.txt` file we can store the raw EDA signal in a pandas dataframe, which allows for easier extraction of the active components, by using the `.loc` method from the Pandas DataFrame object, instead of a for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timings = pd.read_excel(f'{project_dir}\\\\data\\\\information\\\\amsdata_start.xlsx') # Open the file that contains the starting and stop points in a DataFrame\n",
    "\n",
    "for file in txt_files: # for each SCL text file\n",
    "    pp = int(file[2:-3])  # Get the pp id\n",
    "    start_stops = timings.loc[timings.Participant==pp].values[0][1:] # Subset the DataFrame to only the start and stop point for the current PP, and collect those values\n",
    "    \n",
    "    # Open the EDA and ECG file and merge these two based on their time index\n",
    "    eda_data = pd.read_csv(f'{data_dir}\\\\{file}SCL.txt', sep=' ', skiprows=3, names=['timestamp', 'raw_EDA'])\n",
    "    ecg_data = pd.read_csv(f'{data_dir}\\\\{file}ECG.txt', sep=' ', skiprows=3, names=['timestamp', 'raw_ECG'])\n",
    "    data = ecg_data.merge(eda_data, on='timestamp', how='outer')\n",
    "    \n",
    "    \n",
    "    data['timestamp'] = data['timestamp']/1000 # Divide the timestamp collumn by a 1000 since the timestamps are in the txt files are in ms but the starting points from the excel file are in seconds\n",
    "    \n",
    "    freq=round(1/(data.timestamp.values[1] - data.timestamp.values[0])) # Compute the frequency of the signals using the following formula: freq=1/(t_1 - t_2)\n",
    "    \n",
    "    data['pp'] =  pp # Store the PP_id in the DataFrame\n",
    "    \n",
    "    ## Very hard to read code below: Selects the rows from the DataFrame containing the EDA and ECG signal that are between the starting and stop points of the active components\n",
    "    ## This code is faster than looping and appending to arrays. See the comments below for the logic\n",
    "    data = data.loc[((data.timestamp>start_stops[0]) & (data.timestamp<start_stops[1])) # Get each row: (After 1st timepoint in start_stop) AND (before 2nd timepoint in start_stop) OR \n",
    "                    |((data.timestamp>start_stops[2]) & (data.timestamp<start_stops[3])) # (After 3rd timepoint in start_stop) AND (before 4th timepoint in start_stop) OR\n",
    "                    |((data.timestamp>start_stops[4]) & (data.timestamp<start_stops[5])) # And so on...\n",
    "                    |((data.timestamp>start_stops[6]) & (data.timestamp<start_stops[7]))\n",
    "                    |((data.timestamp>start_stops[8]) & (data.timestamp<start_stops[9])),:]\n",
    "    \n",
    "    data.astype('float',copy=False) # Set the entire dataframe as Float for memory reasons (string takes more memory)\n",
    "    \n",
    "    # Reset the index before storing the DataFrame in an HDF file for later use\n",
    "    data.reset_index(inplace=True)\n",
    "    data.to_hdf(f'{project_dir}\\\\data\\\\interim\\\\physiological_all\\\\{pp}.hdf', f'pp{pp}', mode='w')\n",
    "    print(f'pp{pp} done')\n",
    "    \n",
    "print('All done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSST component\n",
    "Below we extract the TSST component of the experiment. From both the `.acq` files and the `.amsdata` files we extract physiological signal from the TSST speech and TSST math component, aswell as the signal inbetween both components. Because the camera is started a bit before the start of the TSST speech component and the recording lasts around 15 to 20 minutes, it is easier to extract the physiological from 3 minutes prior to the start of the TSST speech component till the 20 minutes after the start of the component. This is once again stored in a `.hdf` file.\n",
    "\n",
    "For this component we also add a `t_from_start` column, which indicates for all the other timepoints in the signal how far away (in seconds) it is removed from the start of the TSST component, which we can use it later on to synchronise it to the video data. \n",
    "### .acq files\n",
    "Once again, we can select the components using the digital input channel present in the `.acq` files. The starting point of TSST speech component is indicated by the 5th time the digital input was activated. We can then use this starting point to select all the EDA and ECG signal from 3 minutes prior till 20 minutes post this starting point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for file in acq_files: # For each acq files in the dir\n",
    "    pp = int(file[2:-6]) # Get the pp id\n",
    "    bio = bioread.read_file(data_dir + '\\\\' + file) # Open the physiological file\n",
    "\n",
    "    # Get the EDA, ECG, Time index and Digital input signal(which corresponds to the triggers from the psychopy script)\n",
    "    eda = bio.channels[0].data\n",
    "    ecg = bio.channels[1].data\n",
    "    timestamps = bio.channels[0].time_index\n",
    "    digital_input = np.copy(bio.channels[2].data)\n",
    "    \n",
    "    # Using the Digital input signal, get the start and stop points of the different components in the study\n",
    "    starts = np.where(np.diff(digital_input_org)>0)[0]\n",
    "    stops = np.where(np.diff(digital_input_org)<0)[0]\n",
    "    \n",
    "    # Select the starting point of the TSST Speech component and the stopping point of the TSST Math component\n",
    "    start = starts[4]\n",
    "    stop = stops[6]\n",
    "    \n",
    "    # Subset the EDA, ECG, time index and digital input signal, 3 minutes prior to the start of the speech component and 3 minutes past the end of the speech component \n",
    "    eda = eda[start-(2000*60*3):stop+(2000*60*3)]\n",
    "    ecg = ecg[start-(2000*60*3):stop+(2000*60*3)]\n",
    "    timestamps = timestamps[start-(2000*60*3):stop+(2000*60*3)]\n",
    "    digital_input = digital_input[start-(2000*60*3):stop+(2000*60*3)]\n",
    "    \n",
    "    \n",
    "    data = pd.DataFrame({'timestamp': timestamps,'raw_EDA': eda, 'raw_ECG': ecg, 'digital_input': digital_input}) # Create a DataFrame with the signals stored in the array\n",
    "    \n",
    "    freq=round(1/(data.timestamp.values[1] - data.timestamp.values[0])) # Compute the frequency of the signals using the following formula: freq=1/(t_1 - t_2)\n",
    "    \n",
    "    data['t_from_start'] = data['timestamp'] - (start/freq) # Compute the time between each row in the DataFrame and the starting point\n",
    "    data['pp'] =  pp # Store the PP_id in the DataFrame\n",
    "    data.astype('float',copy=False) # Set the entire dataframe as Float for memory reasons (string takes more memory)\n",
    "    \n",
    "    # Reset the index before storing the DataFrame in an HDF file for later use\n",
    "    data.reset_index(inplace=True)\n",
    "    data.to_hdf(f'{project_dir}\\\\data\\\\interim\\\\physiological\\\\{pp}.hdf', f'pp{pp}', mode='w')\n",
    "    print(f'pp{pp} done')\n",
    "print('All done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .amsdata files\n",
    "As said before the `.amsdata` files (which are extracted and stored in an `.txt` files) do not denote the different components of the experiment along the physiological signal. Instead, the experimenters in the study have indicated the starting points of each component in an excel file. The starting point of the TSST speech component is stored in the `started_TSST.csv` file. We open the file `start_TSST.csv` and store the information inside in a dict called `timings` where you can get the moment in the video of a certain participant (pp) where the TSST component starts in seconds (start) as follows: `start = timings['pp']`.\n",
    "\n",
    "Once agian we we can store the raw EDA signal in a pandas dataframe, which allows for easier extraction of the active components, by using the `.loc` method from the Pandas DataFrame object, instead of a for loop. Likewise to the `.acq` files, we take the subset of the data between 3 minutes prior to the start and 20 minutes after the start. This file is also stored in a `hdf` file in the interim folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the file that contains the starting and stop points for each participant for the start TSST component\n",
    "reader = csv.DictReader(open(project_dir + '\\\\data\\\\information\\\\start_TSST.csv', encoding='utf-8-sig'), delimiter=';')\n",
    "timings = {}\n",
    "for row in reader:\n",
    "    timings[int(row['pp'])] = float(row['start'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in txt_files: # for each SCL text file\n",
    "    pp = int(file[2:-3]) # Get the pp id\n",
    "    start = timings[pp] # Get the starting point of the TSST speech component for this participant\n",
    "    \n",
    "    # Open the EDA and ECG file and merge these two based on their time index\n",
    "    eda_data = pd.read_csv(f'{data_dir}\\\\{file}SCL.txt', sep=' ', skiprows=3, names=['timestamp', 'raw_EDA'])\n",
    "    ecg_data = pd.read_csv(f'{data_dir}\\\\{file}ECG.txt', sep=' ', skiprows=3, names=['timestamp', 'raw_ECG'])\n",
    "    data = ecg_data.merge(eda_data, on='timestamp', how='outer')\n",
    "    \n",
    "    data['timestamp'] = data['timestamp']/1000 # Divide the timestamp collumn by a 1000 since the timestamps are in the txt files are in ms but the starting points from the excel file are in seconds\n",
    "\n",
    "    freq=round(1/(data.timestamp.values[1] - data.timestamp.values[0])) # Compute the frequency of the signals using the following formula: freq=1/(t_1 - t_2)\n",
    "    \n",
    "    data['t_from_start'] =  data['timestamp'] - start # Compute the time between each row in the DataFrame and the starting point\n",
    "    data['pp'] =  pp # Store the PP_id in the DataFrame\n",
    "    \n",
    "    data = data.loc[(data.t_from_start>-180) & (data.t_from_start<1200),:] # Subset the rows 3 minutes prior to the TSST Speech starting point and 20 minutes after this starting point\n",
    "    \n",
    "    data.astype('float',copy=False) # Set the entire dataframe as Float for memory reasons (string takes more memory)\n",
    "    \n",
    "    # Reset the index before storing the DataFrame in an HDF file for later use\n",
    "    data.reset_index(inplace=True)\n",
    "    data.to_hdf(f'{project_dir}\\\\data\\\\interim\\\\physiological\\\\{pp}.hdf', f'pp{pp}', mode='w')\n",
    "    print(f'pp{pp} done')\n",
    "    \n",
    "print('All done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline component"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we want to extract the baseline component of the experiment, since we can use this information for standardisation. This is very very similar to the extraction of the TSST components, where as we now only have to extract one component. The two cells below corresponds to the previous two respectively, in one minor change. We subset only the rows between the starting and end point (minutes after the starting point) of the baseline component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for file in acq_files: # For each acq files in the dir\n",
    "    pp = int(file[2:-6]) # Get the pp id\n",
    "    bio = bioread.read_file(data_dir + '\\\\' + file) # Open the physiological file\n",
    "    \n",
    "    # Get the EDA, ECG, Time index and Digital input signal(which corresponds to the triggers from the psychopy script)\n",
    "    eda = bio.channels[0].data\n",
    "    ecg = bio.channels[1].data\n",
    "    timestamps = bio.channels[0].time_index\n",
    "    digital_input = np.copy(bio.channels[2].data)\n",
    "    \n",
    "    # Using the Digital input signal, get the start and stop points of the different components in the study\n",
    "    starts = np.where(np.diff(digital_input)>0)[0]\n",
    "    stops = np.where(np.diff(digital_input)<0)[0]\n",
    "    \n",
    "    # Select the start and stop point of the baseline component\n",
    "    start = starts[0]\n",
    "    stop = stops[1]\n",
    "    \n",
    "    # Subset the EDA, ECG, time index and digital input signal\n",
    "    eda = eda[start:stop]\n",
    "    ecg = ecg[start:stop]\n",
    "    timestamps = timestamps[start:stop]\n",
    "    digital_input = digital_input[start:stop]\n",
    "\n",
    "    data = pd.DataFrame({'timestamp': timestamps,'raw_EDA': eda, 'raw_ECG': ecg, 'digital_input': digital_input}) # Create a DataFrame with the signals stored in the array\n",
    "    \n",
    "    freq=round(1/(data.timestamp.values[1] - data.timestamp.values[0])) # Compute the frequency of the signals using the following formula: freq=1/(t_1 - t_2)\n",
    "    \n",
    "    data['t_from_start'] = data['timestamp'] - (start/freq) # Compute the time between each row in the DataFrame and the starting point\n",
    "    data['pp'] =  pp # Store the PP_id in the DataFrame\n",
    "    data.astype('float',copy=False) # Set the entire dataframe as Float for memory reasons (string takes more memory)\n",
    "    \n",
    "    # Reset the index before storing the DataFrame in an HDF file for later use\n",
    "    data.reset_index(inplace=True)\n",
    "    data.to_hdf(f'{project_dir}\\\\data\\\\interim\\\\physiological_baseline\\\\{pp}.hdf', f'pp{pp}', mode='w')\n",
    "    print(f'pp{pp} done')\n",
    "print('All done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the file that contains the starting and stop points for each participant for the start TSST component\n",
    "reader = csv.DictReader(open(project_dir + '\\\\data\\\\information\\\\start_Baseline.csv', encoding='utf-8-sig'), delimiter=';')\n",
    "timings = {}\n",
    "for row in reader:\n",
    "    timings[int(row['pp'])] = float(row['start'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in txt_files: # for each SCL text file\n",
    "    pp = int(file[2:-3]) # Get the pp id\n",
    "    start = timings[pp] # Get the starting point of the baseline component for this participant\n",
    "    \n",
    "    # Open the EDA and ECG file and merge these two based on their time index\n",
    "    eda_data = pd.read_csv(f'{data_dir}\\\\{file}SCL.txt', sep=' ', skiprows=3, names=['timestamp', 'raw_EDA'])\n",
    "    ecg_data = pd.read_csv(f'{data_dir}\\\\{file}ECG.txt', sep=' ', skiprows=3, names=['timestamp', 'raw_ECG'])\n",
    "    data = ecg_data.merge(eda_data, on='timestamp', how='outer')\n",
    "    \n",
    "    data['timestamp'] = data['timestamp']/1000 # Divide the timestamp collumn by a 1000 since the timestamps are in the txt files are in ms but the starting points from the excel file are in seconds\n",
    "    \n",
    "    freq=round(1/(data.timestamp.values[1] - data.timestamp.values[0])) # Compute the frequency of the signals using the following formula: freq=1/(t_1 - t_2)\n",
    "    \n",
    "    data['t_from_start'] =  data['timestamp'] - start # Compute the time between each row in the DataFrame and the starting point\n",
    "    data['pp'] =  pp # Store the PP_id in the DataFrame\n",
    "    \n",
    "    data = data.loc[(data.t_from_start>0) & (data.t_from_start<300),:] # Subset the rows from the baseline starting point till 5 minutes after this starting point\n",
    "    data.astype('float',copy=False) # Set the entire dataframe as Float for memory reasons (string takes more memory)\n",
    "    \n",
    "    # Reset the index before storing the DataFrame in an HDF file for later use\n",
    "    data.reset_index(inplace=True)\n",
    "    data.to_hdf(f'{project_dir}\\\\data\\\\interim\\\\physiological_baseline\\\\{pp}.hdf', f'pp{pp}', mode='w')\n",
    "    print(f'pp{pp} done')\n",
    "print('All done!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
