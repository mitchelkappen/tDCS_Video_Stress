{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Window sampling\n",
    "This notebook is responsible for the synchronisation of the physiological and video dataframes created in the previous notebooks. It is also responsible for getting the data samples from these synchronised dataframes, by running a smaller sliding window over these DataFrames and then computing various features and target variables on the selected windows. In the first few cells, some functions are described which implement these different tasks, like getting the different start and end points of the windows and also computing the targets and features. The last two cells are responsible for the actual sampling of all the different DataFrames.\n",
    "#### Requirements\n",
    "If one wants to run this notebook make sure you have created the physiological and video DataFrames, which can be done by running the previous notebooks `1-ak-physio-dataframe` and `2-ak-video-dataframe`. If executed properly, these notebooks should have created two DataFrames, one for physiological signals and one for video signals, for each participant. These DataFrames should be stored in the `data\\interim` directory, in either the `video` or `physiological` subdirectory.\n",
    "\n",
    "Besides the DataFrames, one also needs to have the scripts that contain the functions responsible for the target and feature computation, `targetComputation.py` and `features.py`. These should be in the same directory as the notebooks.\n",
    "\n",
    "Finally, to run the function in from the `targetComputation.py` script one also needs to have run the `3-ak-target-variable` notebook, which is responsible for the csv files that contain information about physiological signals in the baseline component. These should be stored in the `data/information` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from targetComputation import compute_EDA_Targets, compute_ECG_Targets\n",
    "import features as ft\n",
    "from CONSTANTS import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading in the required modules, we store the working directory in a variable called `project_dir`. We then store the folder where the data files are located in a variable called `data_dir`. We also store the location of the subdirectories, which store the video and physiological dataframes in, respectively, `video_dir` and `physio_dir`. We store the video and physiological filenames in different variables. We also create a variable `pps`, which stores the pp ids for the pp for which both the video and physiological dataframes are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = os.getcwd().split('\\\\')[:-1]\n",
    "project_dir = '\\\\'.join(project_dir) # Get the project dir\n",
    "# Get the data dir\n",
    "if Mitchel:\n",
    "    data_dir = 'C:\\\\Users\\\\mitch\\\\OneDrive - UGent\\\\UGent\\\\Projects\\\\7. tDCS_Stress_WM_deSmet\\\\data'\n",
    "    data_dir = 'Z:\\\\ghep_lab\\\\2020_DeSmetKappen_tDCS_Stress_WM_VIDEO\\\\Data'\n",
    "else: \n",
    "    data_dir = project_dir + '\\\\data'\n",
    "\n",
    "video_dir = data_dir+'\\\\interim\\\\video' # Get the video dir\n",
    "physio_dir = data_dir+'\\\\interim\\\\physiological' # Get the physio dir\n",
    "video_files = [file for file in os.listdir(video_dir)] # Get the video files\n",
    "physio_files = [file for file in os.listdir(physio_dir)] # Get the physio files\n",
    "\n",
    "pps = list(set([file[:-8] for file in video_files]).intersection(set([file[:-8] for file in physio_files]))) # Get the intersection of the pp ids in the video files and the pp ids from the physio files\n",
    "pps = sorted([int(pp) for pp in pps]) # Set all the pp ids to int type and sort this list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for sampling\n",
    "After loading the required modules and storing the different location of the data files in variables, we implemented some functions that will perform the sampling of all the DataFrames further below.\n",
    "### Getting the start and end points of a single DataFrame\n",
    "First off the `get_start_end` function. This function finds all the start and end points of a sample in a given video DataFrame, given a window and step size. This function works with any desired window and step size, as longs as they are integers. The function returns a list of tuples, with each tuple reflecting the start and end point of a window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_start_end(data: pd.DataFrame, window_size: int, step_size: int) -> list:\n",
    "    \"\"\"Get start & end points of a video signal DataFrame on a given window size and step size.\n",
    "    Returns a list of tuples (startpoint, endpoint)\n",
    "    \"\"\"\n",
    "    points = [] # Create the list to store the points in\n",
    "    start = data.t_from_start.values[0] # Get the first frame, which acts as the starting point of the first frame\n",
    "    end = start + window_size # Compute the first end point, by adding the desired window size to the starting point\n",
    "    points.append((start, end)) # Add the start and end point to the list of points\n",
    "\n",
    "    while end+step_size < data.t_from_start.values[-1]: # While the end point + the step size does not reach beyond the last frame\n",
    "        start += step_size # Update the new starting point, by adding the step size to the last starting point \n",
    "        end += step_size # Update the new ending point, by adding the step size to the last ending point \n",
    "        points.append((start, end)) # Add this new start and end point to the list of points\n",
    "    \n",
    "    return points # Return the list of points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting one window\n",
    "The function `get_window` subsets one window/sample from a dataframe, based on a given start and end point. Combined with the `get_start_end` function, this functions helps us to gather all the possible windows/samples from a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_window(data: pd.DataFrame, start: int, end: int) -> pd.DataFrame:\n",
    "    \"\"\"Return subset of a DataFrame (window) between a certain start and endpoint.\"\"\"\n",
    "    return data.loc[(data.t_from_start >= start) & (data.t_from_start <= end), :] # Get all the rows after (or equal to) the starting point AND (or equal to) the ending point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the windows\n",
    "Below we have implemented two functions for the processing of respectively a video window and a physiological window. The functions `process_physio_window` and `process_video_window` have as input a window/sample (a subset of DataFrame obtained through the function `get_window`) and compute various features or targets, which are returned in a dict. When we want to compute extra or other features/targets, we can just add the computation in these functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_physio_window(window: pd.DataFrame) -> dict:\n",
    "    \"\"\"Processes the physiological window. Returns a dict containing the computed target variables and the first and last point of the window.\"\"\"\n",
    "    processed_window = {} # Create the dict to store the target variables and other information in\n",
    "    \n",
    "    processed_window['t_start_physio'] = window.t_from_start.values[0] # Get the starting timestamp of this window and add this to the dict\n",
    "    processed_window['t_end_physio'] = window.t_from_start.values[-1] # Get the ending timestamp of this window and add this to the dict\n",
    "    \n",
    "    processed_window = {**processed_window, **compute_EDA_Targets(window)} # Compute the EDA targets by using the function from targetComputation.py and add this to dict\n",
    "    processed_window = {**processed_window, **compute_ECG_Targets(window)} # Compute the ECG targets by using the function from targetComputation.py and add this to dict\n",
    "    \n",
    "    return processed_window # Return the processed physio window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video_window(window: pd.DataFrame) -> dict:\n",
    "    \"\"\"Processes the video window. Returns a dict containing the computed features and the first and last frame of the window.\"\"\"\n",
    "    processed_window = {} # Create the dict to store the target variables and other information in\n",
    "    \n",
    "    processed_window['t_start_video'] = window.t_from_start.values[0] # Get the starting frame of this window and add this to the dict\n",
    "    processed_window['t_end_video'] = window.t_from_start.values[-1] # Get the ending frame of this window and add this to the dict\n",
    "    \n",
    "    ## Below we calculate various features using the functions from features.py, and adding these to the dict\n",
    "    processed_window = {**processed_window, **ft.compute_mean_AUs(window)} # Computation of mean FAU and mean change FAU\n",
    "    processed_window = {**processed_window, **ft.compute_std_AUs(window)} # Computation of std FAU\n",
    "    processed_window = {**processed_window, **ft.compute_arousal(window)} # Computation of arousal\n",
    "    processed_window = {**processed_window, **ft.compute_emotions(window)} # Computation of various emotions\n",
    "    processed_window = {**processed_window, **ft.compute_head_motion(window)} # Computation of std of head motion in different directions\n",
    "    processed_window = {**processed_window, **ft.compute_PD_features(window)} # Computation of various Pupil Diameter (PD) features\n",
    "    processed_window['blink_rate'] = ft.compute_blink_rate(window) # Computation of the blink rate\n",
    "    \n",
    "    return processed_window # Return the processed physio window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the quality of the video window\n",
    "Finally we have created a function that assess the quality of a given video window (subset of video DataFrame). Based on defined rules, it either returns false if the rules are broken, thus the video window is of too low quality to be used as a data sample, or it returns true if none of the rules are broken. If one wants to change the rules on which the decision is made to exclude video data samples, one can do so by changing this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_video_window(window: pd.DataFrame) -> bool:\n",
    "    \"\"\"Checks the video window, based on the defined rules. If the rule is broken we return false and do not use the entire window. Else we return true\"\"\"\n",
    "    global removed # Get access to the variable removed, defined later on, which allows tracking of the amount of removed/declined windows\n",
    "    if (window.confidence >= 0.8).sum()/len(window.confidence) < 0.95: # If less than 95% of the frames in the video window got confidence rating below 80% \n",
    "        removed += 1 # Remove this window, thus adding 1 to the removed variable\n",
    "        return False # And returning False\n",
    "    else: # If no rules were broken\n",
    "        return True # Return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling and processing one participant\n",
    "Below we have implemented the `sample_pp` function, which samples and processes the data of one participant. After reading in the physio and video DataFrame of the participant, it implements the four functions implemented in the previous cells, to sample and process the video and physiological DataFrames. It stores the processed windows in a list of dicts, and returns this at the end of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_pp(physio_data: pd.DataFrame, video_data: pd.DataFrame, window_size: int, step_size: int) -> list:\n",
    "    \"\"\"Samples the data of one specific participant. Returns a list of dicts, where each dict represents a processed window\"\"\"\n",
    "    points = get_start_end(video_data, window_size, step_size) # Get the starting and end points based on the video DataFrame\n",
    "    processed_windows = [] # Create an empty list in which to store the dicts\n",
    "    i = 1 # i represents the ith window of the participant\n",
    "    for point in points: # for each start end point tuple\n",
    "        start, end = point # Get the start and end point\n",
    "        video_window = get_window(video_data, start, end) # Get the video window\n",
    "        if check_video_window(video_window): # If this video window passes the quality checks\n",
    "            physio_window = get_window(physio_data, start, end) # Also get the physio window\n",
    "            \n",
    "            processed_physio_window = process_physio_window(physio_window) # Process the physio window\n",
    "            processed_video_window = process_video_window(video_window) # Process the video window\n",
    "\n",
    "            processed_window = {**processed_video_window, **processed_physio_window} # Add these processed windows together\n",
    "            processed_window['start'] = start # Add the starting point to the processed window dict\n",
    "            processed_window['end'] = end # Add the ending point to the processed window dict\n",
    "            processed_window['pp'] = pp # Add the pp id to the processed window dict\n",
    "            processed_window['pp_window'] = i # Add the window id of this specific pp to the processed window dict \n",
    "            \n",
    "            processed_windows.append(processed_window) # Add the processed window to the list of processed windows\n",
    "        i += 1 # Update the window id\n",
    "    return processed_windows # Return the list of processed windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling the data \n",
    "The following two cells process the data from all the participants, using the above implemented functions.\n",
    "### Loading in the participants\n",
    "In order to speed up the code, we first load in all the DataFrames, and storing these dataframes in dicts, respectively `pp_video` and `pp_physio`. These dicts can be accessed using the participants id. Doing this, takes up a lot of memory, however speeds up the sampling process. If we were to have more than 100 participants, or larger DataFrames, we would however run into memory issues.\n",
    "\n",
    "There are also 2 lines of codes that set a subset of the video dataframe to nan, if those rows have a confidence rating lower then 80%. This is necessary for the function `check_video_window` to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pp:   0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pp_physio = {} # Create a dict to store the physio DataFrames in\n",
    "pp_video = {} # Create a dict to store the video DataFrames in\n",
    "\n",
    "for pp in tqdm(pps, desc='pp', leave=False): # For each of the pp ids\n",
    "    pp_physio[pp] = pd.read_feather(f'{physio_dir}\\\\{pp}.feather') # Read in physio DataFrame and store this in dict\n",
    "    df = pd.read_feather(f'{video_dir}\\\\{pp}.feather') # Read in video DataFrame\n",
    "    cols = [col for col in df.columns if col not in ['frame', 'face_id', 'timestamp', 'confidence', 'success', 'started', 'pp', 't_from_start', 'frames_away_start ']] # Get all the cols that need to be set to nan if < 80%\n",
    "    df.loc[df.confidence<0.8, cols] = np.nan # Set desired cols to nan if confidence < 80%\n",
    "    pp_video[pp] = df # Store DataFrame to dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing all the participants\n",
    "Below we sample all the participants and stored the processed windows in a dataframe, and saving it to the `data\\processed` directory. These DataFrames will be used for the modelling steps in the next notebooks. The variables `window_sizes` and `step_sizes` contain the step and window sizes to sammple DataFrames with. `window_sizes` is a list of ints, where each element represent a window size in seconds. `step_sizes` is a list of floats, where each float is used as a proportion of the current window size to compute the step size: `step_size` = `window_size` * `float`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "129f84908fa7486e914d9b301b5ca7c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "windows:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "steps:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pp:   0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished window size: 180 step size: 180. Sampled a total of 178 windows. Removed total of 158 windows, ~47 percent of all possible windows.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "steps:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pp:   0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished window size: 300 step size: 300. Sampled a total of 98 windows. Removed total of 100 windows, ~50 percent of all possible windows.\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('mode.chained_assignment',None) # Set this options to avoid annoying warnings (Not necessary)\n",
    "window_sizes = [60*3, 60*5] # List of window sizes in seconds\n",
    "step_sizes = [1] # List of step sizes proportionally to seconds\n",
    "\n",
    "for window_size in tqdm(window_sizes, desc='windows'): # For each window size\n",
    "    for step_size in tqdm(step_sizes, desc='steps', leave=False): # For each step size\n",
    "        df = [] # Create a list in which to store the processed windows\n",
    "        step_size *= window_size # Compute the step size\n",
    "        step_size = int(step_size) # Set it to an integer\n",
    "        removed = 0 # Create this to keep track of how many windows are removed\n",
    "        for pp in tqdm(pps, desc='pp', leave=False): # For each participant\n",
    "            df += sample_pp(pp_physio[pp], pp_video[pp], window_size, step_size) # Sample and process all the windows and add this to list of processed windows\n",
    "        df = pd.DataFrame(df) # Create a DataFrame from this list of dicts\n",
    "        df.pp = df['pp'].astype('str') # Set pp to type string\n",
    "        df['window'] = df.index # Set the index as column `window` to have unique window ids for all the windows\n",
    "        print(f'Finished window size: {window_size} step size: {step_size}. Sampled a total of {len(df.pp)} windows. Removed total of {removed} windows, ~{int(((removed)/(removed+len(df.pp)))*100)} percent of all possible windows.') # Print the result of this window and step size\n",
    "        df.to_feather(f\"{data_dir}\\\\processed\\\\window_{window_size}_step_{step_size}.feather\") # Save the DataFrame to desired folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
