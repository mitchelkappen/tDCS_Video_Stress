{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target variables notebook\n",
    "This notebook describes the functions that compute the target variables for the sampled windows in the notebook `4-ak-window-sampling`. In addition, this notebook is responsible for computing various other statistics that are relevant (necessary) for the computation of the target variables, like the mean SCL during the baseline component. These are stored in the `data\\information` directory. \n",
    "\n",
    "#### Requirements\n",
    "If one wants to run this notebook, make sure that you have run the `1-ak-physio-dataframe` notebook. This notebook is responsible for the creation of the physiological DataFrames, stored in `data\\interim`, in the 3 folders `physiological`, `physiological_baseline` and `physiological_all`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import neurokit2 as nk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mitchel = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading in the required modules, we store the working directory in a variable called `project_dir`. We then store the folder where the data files are located in a variable called `data_dir`. We also store the different paths of the directories that hold the physiological DataFrames in variables, aswell as the list of the files in these directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = os.getcwd().split('\\\\')[:-1] \n",
    "project_dir = '\\\\'.join(project_dir) # Get the project dir\n",
    "\n",
    "# Get the data dir\n",
    "if Mitchel:\n",
    "    data_dir = 'C:\\\\Users\\\\mitch\\\\OneDrive - UGent\\\\UGent\\\\Projects\\\\7. tDCS_Stress_WM_deSmet\\\\data'\n",
    "    data_dir = 'Z:\\\\ghep_lab\\\\2020_DeSmetKappen_tDCS_Stress_WM_VIDEO\\\\Data'\n",
    "else: \n",
    "    data_dir = project_dir + '\\\\data'\n",
    "# Get the specific physiological directories and the files in these dirs and store these in respectively named variables\n",
    "physio_dir = data_dir+'\\\\interim\\\\physiological'\n",
    "physio_files = [file for file in os.listdir(physio_dir)]\n",
    "baseline_dir = data_dir + '\\\\interim\\\\physiological_baseline'\n",
    "baseline_files = [file for file in os.listdir(baseline_dir)]\n",
    "all_dir = data_dir + '\\\\interim\\\\physiological_all'\n",
    "all_files = [file for file in os.listdir(all_dir)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute baseline and ALL components statistics\n",
    "The cells below are responsible for the computation of the various statistics that are used for computing the target variables during the window sampling process. \n",
    "\n",
    "#### EDA Statistics\n",
    "The following cells concern the SCL, or Tonic EDA, signal. The first cell contains the function that can calculate the various statistics for the SCL signal. It calculates the mean and std for an arbitrary period of raw EDA signal, aswell as the min and maximum. \n",
    "\n",
    "In the next cell this function is then applied to both the baseline and all DataFrames, to calculate these descriptives statistics. This information is then stored in dataframes, which are stored `data\\information\\SCL stats`. The function used in the window processing to calculate the target variables, uses these DataFrames in its computation. Therefore, the cells below need to be run before one can execute the `4-ak-window-sampling` notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_PP_EDA(physio_data: pd.DataFrame, pp: int) -> dict:\n",
    "    \"\"\"This function computes the mean, std, min and max SCL of a given raw EDA signal. It returns these stats and the pp id in a dict\"\"\"\n",
    "    \n",
    "    processed = {} # Create the dict that will store the stats and is returned at the end of the function\n",
    "    \n",
    "    freq=round(1/(physio_data.timestamp.values[1] - physio_data.timestamp.values[0])) # Calculate the frequency at which the raw EDA signal was sampled \n",
    "    \n",
    "    signals, info = nk.eda_process(physio_data.raw_EDA.dropna(), sampling_rate=freq) # Process the EDA signals using the eda_process function from NeuroKit2\n",
    "    \n",
    "    # Compute the various SCL statistics and store this in a dict, before returning this dict \n",
    "    processed['mean_SCL'] = signals.EDA_Tonic.mean()\n",
    "    processed['std_SCL'] = signals.EDA_Tonic.std()\n",
    "    processed['max_SCL'] = signals.EDA_Tonic.max()\n",
    "    processed['min_SCL'] = signals.EDA_Tonic.min()\n",
    "    processed['pp'] = pp\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the EDA stat for the baseline component\n",
    "df = [] # Create an empty list to store the dicts that will be returned by the compute_PP_EDA function\n",
    "\n",
    "for file in baseline_files: # For each baseline file\n",
    "    data = pd.read_feather(baseline_dir + '\\\\' + file) # Read in the DataFrame\n",
    "    pp = int(file[:-8]) # Get the pp id\n",
    "    df.append(compute_PP_EDA(data, pp)) # Compute the stats and add this to the empty list\n",
    "\n",
    "PP_EDA = pd.DataFrame(df) # Convert this list of dicts into a dataframe\n",
    "\n",
    "## Store the different stats in this dataframe in a csv file each\n",
    "## This way they can be accessed independently and only when necessary\n",
    "pd.DataFrame({'mean_SCL':PP_EDA.mean_SCL.values}, index=PP_EDA.pp).to_csv(data_dir +  '\\\\information\\\\SCL stats\\\\PP_meanSCL_Baseline.csv')\n",
    "pd.DataFrame({'std_SCL':PP_EDA.std_SCL.values}, index=PP_EDA.pp).to_csv(data_dir +  '\\\\information\\\\SCL stats\\\\PP_stdSCL_Baseline.csv')\n",
    "pd.DataFrame({'min_SCL':PP_EDA.min_SCL.values}, index=PP_EDA.pp).to_csv(data_dir +  '\\\\information\\\\SCL stats\\\\PP_minSCL_Baseline.csv')\n",
    "pd.DataFrame({'max_SCL':PP_EDA.max_SCL.values}, index=PP_EDA.pp).to_csv(data_dir +  '\\\\information\\\\SCL stats\\\\PP_maxSCL_Baseline.csv')\n",
    "\n",
    "\n",
    "## Compute the EDA stat for all the active components\n",
    "df = [] # Create an empty list to store the dicts that will be returned by the compute_PP_EDA function\n",
    "for file in all_files: # For each all file\n",
    "    data = pd.read_feather(all_dir + '\\\\' + file) # Read in the DataFrame\n",
    "    pp = int(file[:-8]) # Get the pp id\n",
    "    df.append(compute_PP_EDA(data, pp)) # Compute the stats and add this to the empty list\n",
    "\n",
    "PP_EDA = pd.DataFrame(df) # Convert this list of dicts into a dataframe\n",
    "\n",
    "## Store the different stats in this dataframe in a csv file each (by first creating a separate DataFrame for a stat and the using the to_csv method)\n",
    "## This way they can be accessed independently and only when necessary \n",
    "pd.DataFrame({'mean_SCL':PP_EDA.mean_SCL.values}, index=PP_EDA.pp).to_csv(data_dir +  '\\\\information\\\\SCL stats\\\\PP_meanSCL_all.csv')\n",
    "pd.DataFrame({'std_SCL':PP_EDA.std_SCL.values}, index=PP_EDA.pp).to_csv(data_dir +  '\\\\information\\\\SCL stats\\\\PP_stdSCL_all.csv')\n",
    "pd.DataFrame({'min_SCL':PP_EDA.min_SCL.values}, index=PP_EDA.pp).to_csv(data_dir +  '\\\\information\\\\SCL stats\\\\PP_minSCL_all.csv')\n",
    "pd.DataFrame({'max_SCL':PP_EDA.max_SCL.values}, index=PP_EDA.pp).to_csv(data_dir +  '\\\\information\\\\SCL stats\\\\PP_maxSCL_all.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HRV Statistics\n",
    "The following cells concern the ECG signal, which is used to compute various HRV signals.The first cell contains the function that can calculate the various HRV measures for an arbitrary raw ECG signal. This function computes the meanNN, RMSSD and SDNN HRV measures. \n",
    "\n",
    "In the next cell this function is then applied to both the baseline and all DataFrames, to calculate these HRV measures. This information is then stored in dataframes, which are stored `data\\information\\HRV stats`. The function used in the window processing to compute the target variables, uses these DataFrames in its computation. Therefore, the cells below also need to be run before one can execute the `4-ak-window-sampling` notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_PP_HRV(physio_data: pd.DataFrame, pp: int) -> dict:\n",
    "    \"\"\"This function computes the meanNN, RMSDD and SDNN HRV of a given raw ECG signal. It returns these measures and the pp id in a dict\"\"\"\n",
    "    processed = {} # Create the dict that will store the measures and is returned at the end of the function\n",
    "    \n",
    "    freq=round(1/(physio_data.timestamp.values[1] - physio_data.timestamp.values[0])) # Calculate the frequency at which the raw ECG signal was sampled \n",
    "    \n",
    "    ecg_signals, info = nk.ecg_process(data[\"raw_ECG\"], sampling_rate=freq) # Get the clean ECG signal using the ecg_process function from NeuroKit2\n",
    "    ecg_features = nk.ecg_intervalrelated(ecg_signals) # Compute HRV measures using the ecg_intervalrelated function from NeuroKit2\n",
    "    \n",
    "    # Compute the various SCL statistics and store this in a dict, before returning this dict \n",
    "    processed['HRV_MeanNN'] = ecg_features['HRV_MeanNN'].values[0]\n",
    "    processed['HRV_RMSSD'] = ecg_features['HRV_RMSSD'].values[0]\n",
    "    processed['HRV_SDNN'] = ecg_features['HRV_SDNN'].values[0]\n",
    "    processed['pp'] = pp\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the HRV measures for the baseline component\n",
    "df = [] # Create an empty list to store the dicts that will be returned by the compute_PP_HRV function\n",
    "for file in baseline_files: # For each baseline file\n",
    "    data = pd.read_feather(baseline_dir + '\\\\' + file) # Read in the DataFrame\n",
    "    pp = int(file[:-8]) # Get the pp id\n",
    "    df.append(compute_PP_HRV(data, pp)) # Compute the HRV measures and add the returned dict to the list\n",
    "    \n",
    "PP_ECG = pd.DataFrame(df)# Convert this list of dicts into a dataframe\n",
    "\n",
    "## Store the different stats in this dataframe in a csv file each (by first creating a separate DataFrame for a stat and the using the to_csv method)\n",
    "## This way they can be accessed independently and only when necessary\n",
    "pd.DataFrame({'HRV_RMSSD':PP_ECG.HRV_RMSSD.values}, index=PP_ECG.pp).to_csv(data_dir +  '\\\\information\\\\HRV stats\\\\PP_RMSSD_Baseline.csv')\n",
    "pd.DataFrame({'HRV_MeanNN':PP_ECG.HRV_MeanNN.values}, index=PP_ECG.pp).to_csv(data_dir +  '\\\\information\\\\HRV stats\\\\PP_MeanNN_Baseline.csv')\n",
    "pd.DataFrame({'HRV_SDNN':PP_ECG.HRV_SDNN.values}, index=PP_ECG.pp).to_csv(data_dir +  '\\\\information\\\\HRV stats\\\\PP_SDNN_Baseline.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target variable functions\n",
    "The two cells below contain the functions that are used in the `4-ak-window-sampling` notebook. The functions are also stored in the `targetComputation.py` script from which they are imported. Both functions are very similar to their counterpart that computed the SCL stats and HRV measures in the previous cells. They differ in that they use the computed information to calculate the target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_EDA_Target(physio_data: pd.DataFrame) -> dict:\n",
    "    \"\"\"Computes the EDA Target variables from an abritray dataframe containing the raw EDA signal. Returns these target variables in a dict.\"\"\"\n",
    "    \n",
    "    pp = physio_data.pp.values[0] # Get the pp id\n",
    "    \n",
    "    ## Open the baseline, and all descriptive files, then get the value that corresponds to the current pp id and store these in corresponding variables\n",
    "    ## Baseline descriptives\n",
    "    mean_Baseline = pd.read_csv(data_dir +  '\\\\information\\\\SCL stats\\\\PP_meanSCL_Baseline.csv', index_col=0)['mean_SCL'].to_dict()[pp]\n",
    "    min_Baseline = pd.read_csv(data_dir +  '\\\\information\\\\SCL stats\\\\PP_minSCL_Baseline.csv', index_col=0)['min_SCL'].to_dict()[pp]\n",
    "    ## All Descriptives\n",
    "    mean_all = pd.read_csv(data_dir +  '\\\\information\\\\SCL stats\\\\PP_meanSCL_all.csv', index_col=0)['mean_SCL'].to_dict()[pp]\n",
    "    std_all = pd.read_csv(data_dir +  '\\\\information\\\\SCL stats\\\\PP_stdSCL_all.csv', index_col=0)['std_SCL'].to_dict()[pp]\n",
    "    max_all = pd.read_csv(data_dir +  '\\\\information\\\\SCL stats\\\\PP_maxSCL_all.csv', index_col=0)['max_SCL'].to_dict()[pp]\n",
    "    \n",
    "    processed = {} # Create the dict to store the target variables in and which is returned later in the function\n",
    "    \n",
    "    df = physio_data.dropna() # Drop the empty rows in the function (this occurs due to differences in sampling frequency between ECG and EDA signal in the AMSDATA files)\n",
    "    \n",
    "    freq=round(1/(df.t_from_start.values[1] - df.t_from_start.values[0])) # Calculate the frequency at which the raw EDA signal was sampled \n",
    "    seconds = df.t_from_start.values[-1] - df.t_from_start.values[0] # Calculate the amount seconds the physio signal contains\n",
    "    \n",
    "    signals, info = nk.eda_process(data.raw_EDA.dropna(), sampling_rate=freq) # Process the EDA signals using the eda_process function from NeuroKit2\n",
    "    \n",
    "    ## Compute various EDA target variables and store these in the dict. Also add the pp id to the dict and return this dict\n",
    "    processed['mean_SCL'] = signals.EDA_Tonic.mean() # Compute the mean SCL signal\n",
    "    processed['corrected_mean_SCL'] = processed['mean_SCL'] - mean_Baseline # Compute the corrected mean SCL, by subtracting the mean SCL from the baseline component\n",
    "    processed['range_corrected_mean_SCL'] = ((signals.EDA_Tonic - min_Baseline) / (max_SCL - min_Baseline)).mean() # Compute the range corected min SCL, by Min Max scaling the signal and before computing the mean\n",
    "    processed['standardised_mean_scl'] = ((signals.EDA_Tonic - mean_all) / std_all).mean() # Compute the standarised mean SCL, by standardising using the mean and std SCL throughout all the active components\n",
    "    processed['frequency_NS_SCR'] = len(info['SCR_Peaks'])/seconds * 60 # Compute the frequency in which Non-Stimulus Skin Conductance Responses (NS-SCRs) occured, which is a EDA measures related to the Phasic component\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ECG_Targets(physio_data: pd.DataFrame) -> dict:\n",
    "    \"\"\"Computes the EDA Target variables from an abritray dataframe containing the raw EDA signal. Returns these target variables in a dict.\"\"\"\n",
    "    \n",
    "    pp = physio_data.pp.values[0] # Get the pp id\n",
    "    \n",
    "    # Open the baseline HRV measures DataFrames, and then get the value that corresponds to the current pp id and store these in corresponding variables\n",
    "    HRV_RMSSD_baseline = pd.read_csv(data_dir +  '\\\\information\\\\HRV stats\\\\PP_RMSSD_Baseline.csv', index_col=0)['HRV_RMSSD'].to_dict()[pp]\n",
    "    HRV_MeanNN_baseline = pd.read_csv(data_dir +  '\\\\information\\\\HRV stats\\\\PP_MeanNN_Baseline.csv', index_col=0)['HRV_MeanNN'].to_dict()[pp]\n",
    "    HRV_SDNN_baseline = pd.read_csv(data_dir +  '\\\\information\\\\HRV stats\\\\PP_SDNN_Baseline.csv', index_col=0)['HRV_SDNN'].to_dict()[pp]    \n",
    "    \n",
    "    processed = {} # Create the dict to store the target variables in and which is returned later in the function\n",
    "    \n",
    "    freq=round(1/(physio_data.t_from_start.values[1] - physio_data.t_from_start.values[0])) # Calculate the frequency at which the raw EDA signal was sampled \n",
    "    seconds = physio_data.t_from_start.values[-1] - physio_data.t_from_start.values[0] # Calculate the amount seconds the physio signal contains\n",
    "    \n",
    "    ecg_signals, info = nk.ecg_process(data[\"raw_ECG\"], sampling_rate=freq) # Get the clean ECG signal using the ecg_process function from neurokit2    \n",
    "    ecg_features = nk.ecg_intervalrelated(ecg_signals) # Compute HRV measures using the ecg_intervalrelated function from NeuroKit2\n",
    "    \n",
    "    ## Compute various HRV target variables and store these in the dict. Also add the pp id to the dict and return this dict\n",
    "    processed['HRV_MeanNN'] = ecg_features['HRV_MeanNN'].values[0] # Store the mean of the time interval between the NN peaks\n",
    "    processed['HRV_RMSSD'] = ecg_features['HRV_RMSSD'].values[0] # Store the Root Mean Squared Standard deviation of the time interval between the NN peaks \n",
    "    processed['HRV_SDNN'] = ecg_features['HRV_SDNN'].values[0] # Store the standard deviation of the time interval between the NN peaks\n",
    "    processed['HRV_MeanNN_corrected'] = processed['HRV_MeanNN'] - HRV_MeanNN_baseline # Correct the meanNN by subtracting with the meanNN from the baseline component and store this \n",
    "    processed['HRV_RMSSD_corrected'] = processed['HRV_RMSSD'] - HRV_RMSSD_baseline # Correct the RMSSD by subtracting with the RMSSD from the baseline component and store this\n",
    "    processed['HRV_SDNN_corrected'] = processed['HRV_SDNN'] - HRV_SDNN_baseline # Correct the SDNN by subtracting with the SDNN from the baseline component and store this\n",
    "    return processed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
