{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Dataframe creation\n",
    "This notebook loads in the csv files that contain the information extracted by OpenFace from the videos. Each csv file is then loaded into a pandas dataFrame. To this dataframe we add columns containing information about the start (moment) of the TSST speech component. The dataframe is then stored in the `interim` folder as a `.hdf`, for use in the sampling and feature computation steps later on.\n",
    "\n",
    "#### Requirements\n",
    "If one wants to run this notebook, one needs to have run the `raw-video-extraction.py` script. The resulting `csv` files need to be stored in `data\\raw\\Video_Features`.\n",
    "\n",
    "Next one, also needs the timing csv file, which denotes the second where the participant starts with the TSST Speech component. This file needs to be stored `data\\information\\` and be called `start_sentence.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading in the required modules, we store the working directory in a variable called `project_dir`. We then store the folder where the data files are located in a variable called `data_dir`. We create a variable that contains the specific names of all the csv files, `raw_feature_files`. We also put the location in which the future created dataframes need to be saved in a variable called `processed_dir`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = os.getcwd().split('\\\\')[:-1]\n",
    "project_dir = '\\\\'.join(project_dir) # Get the project dir\n",
    "data_dir = project_dir + '\\\\data' # Get the data dir\n",
    "processed_dir = data_dir + '\\\\raw\\\\Video_features' # Get the dir that contains the processed video features csv files\n",
    "raw_feature_files = [file for file in os.listdir(processed_dir) if file.endswith('csv')] # Get all the csv files in the specific data dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We open the file `start_sentence.csv`, which contain the starting moments of the TSST speech component of each participant. We store this in a dict called `timings` where you can get the moment in the video of a certain participant (pp) where the TSST component starts in seconds (start) as follows:\n",
    "\n",
    "`start = timings['pp']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = csv.DictReader(open(project_dir + '\\\\data\\\\information\\\\start_sentence.csv', encoding='utf-8-sig'), delimiter=';') # Open the file that contains the starting points of the TSST component in the videos\n",
    "timings = {}\n",
    "for row in reader:\n",
    "    timings[int(row['pp'])] = int(row['start']) # Store this information in a dict for later use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then load in each csv file into a dataframe one by one. We add some information about the participant. Each line corresponds to a single frame in the video and contains the information about that frame extracted by OpenFace. We add to this dataframe a column called `started`, which is `1` if the participant already started the TSST speech component and `0` if nott. We also added information about the how many frames and seconds a specific frame (row) was from the frame in which the TSST speech component started, which can be found in the columns `t_from_start` (seconds) and `frames_away_start` (frames). Each dataframes is then saved in the interim folder as a `.hdf` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pp2 done\n",
      "pp3 done\n",
      "pp4 done\n",
      "pp5 done\n",
      "pp10 done\n",
      "pp11 done\n",
      "pp12 done\n",
      "pp13 done\n",
      "pp14 done\n",
      "pp17 done\n",
      "pp18 done\n",
      "pp19 done\n",
      "pp21 done\n",
      "pp43 done\n",
      "pp62 done\n",
      "pp68 done\n",
      "pp69 done\n",
      "pp70 done\n",
      "pp71 done\n",
      "pp76 done\n",
      "pp77 done\n",
      "pp82 done\n",
      "pp84 done\n",
      "pp86 done\n",
      "pp90 done\n",
      "pp91 done\n",
      "pp92 done\n",
      "pp93 done\n",
      "pp94 done\n",
      "pp95 done\n",
      "pp96 done\n",
      "pp97 done\n",
      "pp98 done\n",
      "pp99 done\n",
      "pp100 done\n",
      "pp101 done\n",
      "pp102 done\n",
      "pp103 done\n",
      "pp104 done\n",
      "pp106 done\n",
      "pp107 done\n",
      "pp109 done\n",
      "pp110 done\n",
      "pp113 done\n",
      "pp114 done\n",
      "pp115 done\n",
      "pp117 done\n",
      "pp118 done\n",
      "pp119 done\n",
      "pp120 done\n",
      "pp121 done\n",
      "pp122 done\n",
      "pp123 done\n",
      "pp125 done\n",
      "pp126 done\n",
      "pp127 done\n",
      "pp128 done\n",
      "pp129 done\n",
      "pp130 done\n",
      "pp133 done\n",
      "pp134 done\n",
      "pp135 done\n",
      "pp136 done\n",
      "pp138 done\n",
      "pp139 done\n",
      "pp143 done\n",
      "All done!\n"
     ]
    }
   ],
   "source": [
    "for csv_file in raw_feature_files: # For each csv file\n",
    "    new_data = pd.read_csv(processed_dir + '\\\\' + csv_file) # Open the file as a DataFrame\n",
    "    new_data.columns = [col.strip(' ') for col in new_data.columns] # Remove the blank spaces from the column names (This is the result of how OpenFace exports the csv Files)\n",
    "    \n",
    "    pp = int(csv_file[4:7]) # Get the pp id    \n",
    "    new_data['pp'] = pp # Add this to the DataFrame\n",
    "    \n",
    "    # Add a column `started` which is 0 for the rows when the pp did not yet the TSST speech, and 1 if the pp did start\n",
    "    new_data['started'] = 0 \n",
    "    new_data.loc[(new_data.timestamp >= timings[pp]), 'started'] = 1 # The timing information (when did the pp start) is retrieved from the timings dict using the pp id\n",
    "    \n",
    "    ## Add a column `frames_away_start` & `t_from_start` to denote how far each row is from the frame in which the pp started the TSST speech component\n",
    "    ## We need these columns, together with the pp id column to synchronise the physiological and video DataFrame\n",
    "    frame_at_start = new_data.loc[new_data.started==1, 'frame'].values[0] # First find the exact frame in which the participant started\n",
    "    new_data.loc[:, 'frames_away_start'] = new_data.loc[:, 'frame'] - frame_at_start # Compute how far away each frame is from this starting frame by subtracting this from the column `frame`\n",
    "    new_data['t_from_start'] = new_data['frames_away_start']/25 # Add the column `t_from_start`, by deviding `frames_away_start` by 25, which denotes how many seconds each frame is from the starting point\n",
    "    \n",
    "    new_data.astype('float',copy=False)# Set the entire dataframe as Float for memory reasons (string takes more memory)\n",
    "    \n",
    "    # Reset the index before storing the DataFrame in an HDF file for later use\n",
    "    new_data.reset_index(inplace=True)\n",
    "    new_data.to_hdf(data_dir+ '\\\\interim\\\\video\\\\' + f'{pp}.hdf', f'pp{pp}', mode='w')\n",
    "    print(f'pp{pp} done')\n",
    "print('All done!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
